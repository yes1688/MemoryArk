package services

import (
	"context"
	"fmt"
	"io"
	"math/rand"
	"os"
	"path/filepath"
	"sync"
	"testing"
	"time"

	"gorm.io/driver/sqlite"
	"gorm.io/gorm"
	"gorm.io/gorm/logger"

	"memoryark/internal/models"
)

// TestStreamingExportService ä¸²æµåŒ¯å‡ºæœå‹™è² è¼‰æ¸¬è©¦å¥—ä»¶
type TestStreamingExportService struct {
	db          *gorm.DB
	tempDir     string
	testFiles   []models.File
	totalSize   int64
}

// ExportPerformanceMetrics åŒ¯å‡ºæ•ˆèƒ½æŒ‡æ¨™
type ExportPerformanceMetrics struct {
	TotalFiles      int           `json:"total_files"`
	TotalSize       int64         `json:"total_size_bytes"`
	Duration        time.Duration `json:"duration_ms"`
	Throughput      float64       `json:"throughput_mb_per_sec"`
	FilesPerSecond  float64       `json:"files_per_second"`
	MemoryUsage     int64         `json:"memory_usage_bytes"`
	ConcurrentUsers int           `json:"concurrent_users"`
	Success         bool          `json:"success"`
	ErrorRate       float64       `json:"error_rate"`
}

// setupExportLoadTest è¨­ç½®åŒ¯å‡ºè² è¼‰æ¸¬è©¦ç’°å¢ƒ
func setupExportLoadTest(t *testing.T) *TestStreamingExportService {
	// å‰µå»ºæ¸¬è©¦è³‡æ–™åº«
	db, err := gorm.Open(sqlite.Open(":memory:"), &gorm.Config{
		Logger: logger.Default.LogLevel(logger.Silent),
	})
	if err != nil {
		t.Fatalf("Failed to connect to test database: %v", err)
	}

	// åŸ·è¡Œé·ç§»
	err = db.AutoMigrate(&models.File{}, &models.User{}, &models.Category{}, &models.ExportJob{})
	if err != nil {
		t.Fatalf("Failed to migrate database: %v", err)
	}

	// å‰µå»ºæ¸¬è©¦ç”¨æˆ¶
	user := models.User{
		Email:  "test@example.com",
		Name:   "Test User",
		Role:   "user",
		Status: "approved",
	}
	if err := db.Create(&user).Error; err != nil {
		t.Fatalf("Failed to create test user: %v", err)
	}

	// å‰µå»ºæ¸¬è©¦åˆ†é¡
	category := models.Category{
		Name:      "æ¸¬è©¦åˆ†é¡",
		CreatedBy: 1,
	}
	if err := db.Create(&category).Error; err != nil {
		t.Fatalf("Failed to create test category: %v", err)
	}

	// å‰µå»ºè‡¨æ™‚ç›®éŒ„
	tempDir, err := os.MkdirTemp("", "export_load_test_*")
	if err != nil {
		t.Fatalf("Failed to create temp directory: %v", err)
	}

	return &TestStreamingExportService{
		db:      db,
		tempDir: tempDir,
	}
}

// cleanup æ¸…ç†æ¸¬è©¦ç’°å¢ƒ
func (tses *TestStreamingExportService) cleanup() {
	os.RemoveAll(tses.tempDir)
}

// generateTestFiles ç”Ÿæˆæ¸¬è©¦æª”æ¡ˆ
func (tses *TestStreamingExportService) generateTestFiles(fileCount int, avgSizeKB int) error {
	tses.testFiles = make([]models.File, 0, fileCount)
	tses.totalSize = 0

	for i := 0; i < fileCount; i++ {
		// éš¨æ©Ÿæª”æ¡ˆå¤§å° (50% - 150% of avgSize)
		size := int64(avgSizeKB*1024) + rand.Int63n(int64(avgSizeKB*1024)) - int64(avgSizeKB*512)
		if size < 1024 {
			size = 1024 // æœ€å° 1KB
		}

		// å‰µå»ºå¯¦é«”æª”æ¡ˆ
		fileName := fmt.Sprintf("test_file_%d.dat", i)
		filePath := filepath.Join(tses.tempDir, fileName)

		file, err := os.Create(filePath)
		if err != nil {
			return fmt.Errorf("failed to create file %s: %v", fileName, err)
		}

		// å¯«å…¥éš¨æ©Ÿæ•¸æ“š
		buffer := make([]byte, 4096)
		written := int64(0)
		for written < size {
			n := len(buffer)
			if size-written < int64(n) {
				n = int(size - written)
			}
			rand.Read(buffer[:n])
			if _, err := file.Write(buffer[:n]); err != nil {
				file.Close()
				return fmt.Errorf("failed to write to file %s: %v", fileName, err)
			}
			written += int64(n)
		}
		file.Close()

		// å‰µå»ºæª”æ¡ˆè¨˜éŒ„
		fileRecord := models.File{
			Name:         fileName,
			OriginalName: fileName,
			FilePath:     filePath,
			VirtualPath:  "/" + fileName,
			FileSize:     size,
			MimeType:     "application/octet-stream",
			CategoryID:   func() *uint { id := uint(1); return &id }(),
			UploadedBy:   1,
			IsDirectory:  false,
			IsDeleted:    false,
		}

		if err := tses.db.Create(&fileRecord).Error; err != nil {
			return fmt.Errorf("failed to create file record for %s: %v", fileName, err)
		}

		tses.testFiles = append(tses.testFiles, fileRecord)
		tses.totalSize += size
	}

	return nil
}

// simulateExportJob æ¨¡æ“¬åŒ¯å‡ºä»»å‹™
func (tses *TestStreamingExportService) simulateExportJob(fileIDs []uint, ctx context.Context) (*ExportPerformanceMetrics, error) {
	startTime := time.Now()

	// å‰µå»ºåŒ¯å‡ºä»»å‹™è¨˜éŒ„
	job := models.ExportJob{
		JobID:          fmt.Sprintf("test_job_%d", time.Now().UnixNano()),
		UserID:         1,
		Status:         "processing",
		TotalFiles:     len(fileIDs),
		ProcessedFiles: 0,
		TotalSize:      tses.totalSize,
		ProcessedSize:  0,
		ExportFormat:   "zip",
	}

	if err := tses.db.Create(&job).Error; err != nil {
		return nil, fmt.Errorf("failed to create export job: %v", err)
	}

	// æ¨¡æ“¬æª”æ¡ˆè™•ç†éç¨‹
	var processedFiles int
	var processedSize int64
	var memUsage int64

	for i, fileID := range fileIDs {
		select {
		case <-ctx.Done():
			return &ExportPerformanceMetrics{
				Success: false,
			}, ctx.Err()
		default:
		}

		// æ¨¡æ“¬æª”æ¡ˆè®€å–å’Œå£“ç¸®
		var file models.File
		if err := tses.db.First(&file, fileID).Error; err != nil {
			continue
		}

		// æ¨¡æ“¬è®€å–æª”æ¡ˆ
		if _, err := os.Stat(file.FilePath); err != nil {
			continue
		}

		// æ¨¡æ“¬å£“ç¸®éç¨‹ï¼ˆè®€å–æª”æ¡ˆå…§å®¹ï¼‰
		f, err := os.Open(file.FilePath)
		if err != nil {
			continue
		}

		buffer := make([]byte, 32*1024) // 32KB buffer
		for {
			n, err := f.Read(buffer)
			if err == io.EOF {
				break
			}
			if err != nil {
				f.Close()
				continue
			}
			// æ¨¡æ“¬å£“ç¸®è™•ç†æ™‚é–“
			time.Sleep(time.Microsecond * 10)
			memUsage += int64(n)
		}
		f.Close()

		processedFiles++
		processedSize += file.FileSize

		// æ›´æ–°é€²åº¦ï¼ˆæ¯10å€‹æª”æ¡ˆæ›´æ–°ä¸€æ¬¡ï¼‰
		if i%10 == 0 {
			job.ProcessedFiles = processedFiles
			job.ProcessedSize = processedSize
			job.Progress = int(float64(processedFiles) / float64(len(fileIDs)) * 100)
			tses.db.Save(&job)
		}
	}

	duration := time.Since(startTime)

	// è¨ˆç®—æ•ˆèƒ½æŒ‡æ¨™
	throughputMBPS := float64(processedSize) / (1024 * 1024) / duration.Seconds()
	filesPerSecond := float64(processedFiles) / duration.Seconds()

	// å®Œæˆä»»å‹™
	job.Status = "completed"
	job.ProcessedFiles = processedFiles
	job.ProcessedSize = processedSize
	job.Progress = 100
	job.CompletedAt = func() *time.Time { t := time.Now(); return &t }()
	tses.db.Save(&job)

	return &ExportPerformanceMetrics{
		TotalFiles:      len(fileIDs),
		TotalSize:       processedSize,
		Duration:        duration,
		Throughput:      throughputMBPS,
		FilesPerSecond:  filesPerSecond,
		MemoryUsage:     memUsage,
		ConcurrentUsers: 1,
		Success:         true,
		ErrorRate:       0.0,
	}, nil
}

// TestSmallFileExport æ¸¬è©¦å°æª”æ¡ˆåŒ¯å‡ºï¼ˆ1000å€‹æª”æ¡ˆï¼Œå¹³å‡10KBï¼‰
func TestSmallFileExport(t *testing.T) {
	tses := setupExportLoadTest(t)
	defer tses.cleanup()

	// ç”Ÿæˆ1000å€‹å°æª”æ¡ˆ
	if err := tses.generateTestFiles(1000, 10); err != nil {
		t.Fatalf("Failed to generate test files: %v", err)
	}

	// ç²å–æª”æ¡ˆIDåˆ—è¡¨
	fileIDs := make([]uint, len(tses.testFiles))
	for i, file := range tses.testFiles {
		fileIDs[i] = file.ID
	}

	// åŸ·è¡ŒåŒ¯å‡ºæ¸¬è©¦
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cancel()

	metrics, err := tses.simulateExportJob(fileIDs, ctx)
	if err != nil {
		t.Fatalf("Export job failed: %v", err)
	}

	// é©—è­‰æ•ˆèƒ½æŒ‡æ¨™
	if !metrics.Success {
		t.Errorf("Export job should succeed")
	}

	if metrics.FilesPerSecond < 50 {
		t.Errorf("Files per second too low: %.2f (expected > 50)", metrics.FilesPerSecond)
	}

	if metrics.Throughput < 0.5 {
		t.Errorf("Throughput too low: %.2f MB/s (expected > 0.5)", metrics.Throughput)
	}

	t.Logf("âœ… Small file export test passed")
	t.Logf("ğŸ“Š Files: %d, Size: %.2f MB, Duration: %v", 
		metrics.TotalFiles, float64(metrics.TotalSize)/(1024*1024), metrics.Duration)
	t.Logf("ğŸš€ Throughput: %.2f MB/s, Files/sec: %.2f", 
		metrics.Throughput, metrics.FilesPerSecond)
}

// TestLargeFileExport æ¸¬è©¦å¤§æª”æ¡ˆåŒ¯å‡ºï¼ˆ100å€‹æª”æ¡ˆï¼Œå¹³å‡5MBï¼‰
func TestLargeFileExport(t *testing.T) {
	tses := setupExportLoadTest(t)
	defer tses.cleanup()

	// ç”Ÿæˆ100å€‹å¤§æª”æ¡ˆ
	if err := tses.generateTestFiles(100, 5*1024); err != nil {
		t.Fatalf("Failed to generate test files: %v", err)
	}

	fileIDs := make([]uint, len(tses.testFiles))
	for i, file := range tses.testFiles {
		fileIDs[i] = file.ID
	}

	// åŸ·è¡ŒåŒ¯å‡ºæ¸¬è©¦
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Minute)
	defer cancel()

	metrics, err := tses.simulateExportJob(fileIDs, ctx)
	if err != nil {
		t.Fatalf("Export job failed: %v", err)
	}

	// é©—è­‰æ•ˆèƒ½æŒ‡æ¨™
	if !metrics.Success {
		t.Errorf("Export job should succeed")
	}

	if metrics.FilesPerSecond < 1 {
		t.Errorf("Files per second too low: %.2f (expected > 1)", metrics.FilesPerSecond)
	}

	if metrics.Throughput < 10 {
		t.Errorf("Throughput too low: %.2f MB/s (expected > 10)", metrics.Throughput)
	}

	t.Logf("âœ… Large file export test passed")
	t.Logf("ğŸ“Š Files: %d, Size: %.2f MB, Duration: %v", 
		metrics.TotalFiles, float64(metrics.TotalSize)/(1024*1024), metrics.Duration)
	t.Logf("ğŸš€ Throughput: %.2f MB/s, Files/sec: %.2f", 
		metrics.Throughput, metrics.FilesPerSecond)
}

// TestMixedFileExport æ¸¬è©¦æ··åˆæª”æ¡ˆåŒ¯å‡ºï¼ˆ500å€‹æª”æ¡ˆï¼Œå¤§å°ä¸ä¸€ï¼‰
func TestMixedFileExport(t *testing.T) {
	tses := setupExportLoadTest(t)
	defer tses.cleanup()

	// ç”Ÿæˆæ··åˆå¤§å°çš„æª”æ¡ˆ
	if err := tses.generateTestFiles(500, 500); err != nil { // å¹³å‡500KB
		t.Fatalf("Failed to generate test files: %v", err)
	}

	fileIDs := make([]uint, len(tses.testFiles))
	for i, file := range tses.testFiles {
		fileIDs[i] = file.ID
	}

	ctx, cancel := context.WithTimeout(context.Background(), 8*time.Minute)
	defer cancel()

	metrics, err := tses.simulateExportJob(fileIDs, ctx)
	if err != nil {
		t.Fatalf("Export job failed: %v", err)
	}

	if !metrics.Success {
		t.Errorf("Export job should succeed")
	}

	t.Logf("âœ… Mixed file export test passed")
	t.Logf("ğŸ“Š Files: %d, Size: %.2f MB, Duration: %v", 
		metrics.TotalFiles, float64(metrics.TotalSize)/(1024*1024), metrics.Duration)
	t.Logf("ğŸš€ Throughput: %.2f MB/s, Files/sec: %.2f", 
		metrics.Throughput, metrics.FilesPerSecond)
}

// TestConcurrentExports æ¸¬è©¦ä¸¦ç™¼åŒ¯å‡º
func TestConcurrentExports(t *testing.T) {
	tses := setupExportLoadTest(t)
	defer tses.cleanup()

	// ç”Ÿæˆæ¸¬è©¦æª”æ¡ˆ
	if err := tses.generateTestFiles(200, 100); err != nil {
		t.Fatalf("Failed to generate test files: %v", err)
	}

	fileIDs := make([]uint, len(tses.testFiles))
	for i, file := range tses.testFiles {
		fileIDs[i] = file.ID
	}

	// ä¸¦ç™¼æ¸¬è©¦åƒæ•¸
	concurrentUsers := 5
	var wg sync.WaitGroup
	var mu sync.Mutex
	results := make([]*ExportPerformanceMetrics, 0, concurrentUsers)

	startTime := time.Now()

	// å•Ÿå‹•ä¸¦ç™¼åŒ¯å‡ºä»»å‹™
	for i := 0; i < concurrentUsers; i++ {
		wg.Add(1)
		go func(userID int) {
			defer wg.Done()

			ctx, cancel := context.WithTimeout(context.Background(), 10*time.Minute)
			defer cancel()

			metrics, err := tses.simulateExportJob(fileIDs, ctx)
			if err != nil {
				t.Errorf("Concurrent export %d failed: %v", userID, err)
				return
			}

			metrics.ConcurrentUsers = concurrentUsers
			
			mu.Lock()
			results = append(results, metrics)
			mu.Unlock()
		}(i)
	}

	wg.Wait()
	totalDuration := time.Since(startTime)

	// åˆ†æä¸¦ç™¼æ•ˆèƒ½
	if len(results) != concurrentUsers {
		t.Errorf("Expected %d successful exports, got %d", concurrentUsers, len(results))
	}

	var totalThroughput float64
	var successCount int

	for _, result := range results {
		if result.Success {
			successCount++
			totalThroughput += result.Throughput
		}
	}

	avgThroughput := totalThroughput / float64(successCount)
	
	// é©—è­‰ä¸¦ç™¼æ•ˆèƒ½ä¸æœƒåš´é‡é™ç´š
	if avgThroughput < 1.0 {
		t.Errorf("Average throughput too low under concurrent load: %.2f MB/s", avgThroughput)
	}

	t.Logf("âœ… Concurrent export test passed")
	t.Logf("ğŸ‘¥ Concurrent users: %d, Success rate: %.1f%%", 
		concurrentUsers, float64(successCount)/float64(concurrentUsers)*100)
	t.Logf("â±ï¸  Total duration: %v, Avg throughput: %.2f MB/s", 
		totalDuration, avgThroughput)
}

// TestExportTimeout æ¸¬è©¦åŒ¯å‡ºè¶…æ™‚è™•ç†
func TestExportTimeout(t *testing.T) {
	tses := setupExportLoadTest(t)
	defer tses.cleanup()

	// ç”Ÿæˆå¤§é‡æª”æ¡ˆä»¥è§¸ç™¼è¶…æ™‚
	if err := tses.generateTestFiles(50, 1024); err != nil { // 50å€‹ 1MB æª”æ¡ˆ
		t.Fatalf("Failed to generate test files: %v", err)
	}

	fileIDs := make([]uint, len(tses.testFiles))
	for i, file := range tses.testFiles {
		fileIDs[i] = file.ID
	}

	// è¨­ç½®çŸ­è¶…æ™‚æ™‚é–“
	ctx, cancel := context.WithTimeout(context.Background(), 100*time.Millisecond)
	defer cancel()

	metrics, err := tses.simulateExportJob(fileIDs, ctx)
	
	// æ‡‰è©²å› ç‚ºè¶…æ™‚è€Œå¤±æ•—
	if err == nil {
		t.Errorf("Expected timeout error, but export succeeded")
	}

	if metrics != nil && metrics.Success {
		t.Errorf("Export should fail due to timeout")
	}

	t.Logf("âœ… Export timeout test passed - correctly handled timeout")
}

// TestMemoryUsage æ¸¬è©¦è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
func TestMemoryUsage(t *testing.T) {
	tses := setupExportLoadTest(t)
	defer tses.cleanup()

	// ç”Ÿæˆä¸­ç­‰æ•¸é‡çš„æª”æ¡ˆ
	if err := tses.generateTestFiles(300, 200); err != nil {
		t.Fatalf("Failed to generate test files: %v", err)
	}

	fileIDs := make([]uint, len(tses.testFiles))
	for i, file := range tses.testFiles {
		fileIDs[i] = file.ID
	}

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cancel()

	// è¨˜éŒ„é–‹å§‹æ™‚çš„è¨˜æ†¶é«”ç‹€æ³
	var startMem, endMem runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&startMem)

	metrics, err := tses.simulateExportJob(fileIDs, ctx)
	if err != nil {
		t.Fatalf("Export job failed: %v", err)
	}

	runtime.GC()
	runtime.ReadMemStats(&endMem)

	// è¨ˆç®—è¨˜æ†¶é«”å¢é•·
	memGrowth := endMem.Alloc - startMem.Alloc
	memPerFile := float64(memGrowth) / float64(len(fileIDs))

	// é©—è­‰è¨˜æ†¶é«”ä½¿ç”¨åˆç†ï¼ˆæ¯å€‹æª”æ¡ˆä¸è¶…é1MBè¨˜æ†¶é«”ï¼‰
	if memPerFile > 1024*1024 {
		t.Errorf("Memory usage too high: %.2f bytes per file", memPerFile)
	}

	t.Logf("âœ… Memory usage test passed")
	t.Logf("ğŸ’¾ Memory growth: %d bytes, Per file: %.2f bytes", 
		memGrowth, memPerFile)
	t.Logf("ğŸ“Š Files: %d, Total size: %.2f MB", 
		metrics.TotalFiles, float64(metrics.TotalSize)/(1024*1024))
}

// BenchmarkExportPerformance åŒ¯å‡ºæ•ˆèƒ½åŸºæº–æ¸¬è©¦
func BenchmarkExportPerformance(b *testing.B) {
	tses := setupExportLoadTest(&testing.T{})
	defer tses.cleanup()

	// ç”ŸæˆåŸºæº–æ¸¬è©¦æª”æ¡ˆ
	if err := tses.generateTestFiles(100, 50); err != nil {
		b.Fatalf("Failed to generate test files: %v", err)
	}

	fileIDs := make([]uint, len(tses.testFiles))
	for i, file := range tses.testFiles {
		fileIDs[i] = file.ID
	}

	b.ResetTimer()

	for i := 0; i < b.N; i++ {
		ctx, cancel := context.WithTimeout(context.Background(), 2*time.Minute)
		
		_, err := tses.simulateExportJob(fileIDs, ctx)
		if err != nil {
			b.Errorf("Benchmark export failed: %v", err)
		}
		
		cancel()
	}
}

// æ·»åŠ  runtime åŒ…å°å…¥
import "runtime"