package services

import (
	"crypto/sha256"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"testing"
	"time"

	"gorm.io/driver/sqlite"
	"gorm.io/gorm"
	"gorm.io/gorm/logger"

	"memoryark/internal/models"
)

// TestDeduplicationService æª”æ¡ˆå»é‡æœå‹™æ¸¬è©¦å¥—ä»¶
type TestDeduplicationService struct {
	db          *gorm.DB
	tempDir     string
	testFiles   map[string]string // filename -> content
	testHashes  map[string]string // filename -> hash
}

// setupTestEnvironment è¨­ç½®æ¸¬è©¦ç’°å¢ƒ
func setupTestEnvironment(t *testing.T) *TestDeduplicationService {
	// å‰µå»ºè‡¨æ™‚è³‡æ–™åº«
	tempDB := ":memory:"
	db, err := gorm.Open(sqlite.Open(tempDB), &gorm.Config{
		Logger: logger.Default.LogLevel(logger.Silent),
	})
	if err != nil {
		t.Fatalf("Failed to connect to test database: %v", err)
	}

	// åŸ·è¡Œè³‡æ–™åº«é·ç§»
	err = db.AutoMigrate(&models.File{}, &models.User{}, &models.Category{})
	if err != nil {
		t.Fatalf("Failed to migrate test database: %v", err)
	}

	// å‰µå»ºè‡¨æ™‚ç›®éŒ„
	tempDir, err := os.MkdirTemp("", "dedup_test_*")
	if err != nil {
		t.Fatalf("Failed to create temp directory: %v", err)
	}

	// æº–å‚™æ¸¬è©¦æª”æ¡ˆå…§å®¹
	testFiles := map[string]string{
		"file1.txt":     "This is the content of file 1",
		"file2.txt":     "This is the content of file 2", 
		"file1_dup.txt": "This is the content of file 1", // èˆ‡ file1.txt ç›¸åŒ
		"file3.bin":     "Binary content here",
		"file3_dup.bin": "Binary content here", // èˆ‡ file3.bin ç›¸åŒ
		"empty.txt":     "", // ç©ºæª”æ¡ˆ
		"empty_dup.txt": "", // å¦ä¸€å€‹ç©ºæª”æ¡ˆ
	}

	// è¨ˆç®— SHA256 é›œæ¹Šå€¼
	testHashes := make(map[string]string)
	for filename, content := range testFiles {
		hash := sha256.Sum256([]byte(content))
		testHashes[filename] = fmt.Sprintf("%x", hash)
	}

	// å‰µå»ºæ¸¬è©¦ç”¨æˆ¶
	user := models.User{
		Email:  "test@example.com",
		Name:   "Test User",
		Role:   "user",
		Status: "approved",
	}
	if err := db.Create(&user).Error; err != nil {
		t.Fatalf("Failed to create test user: %v", err)
	}

	return &TestDeduplicationService{
		db:         db,
		tempDir:    tempDir,
		testFiles:  testFiles,
		testHashes: testHashes,
	}
}

// cleanup æ¸…ç†æ¸¬è©¦ç’°å¢ƒ
func (tds *TestDeduplicationService) cleanup() {
	os.RemoveAll(tds.tempDir)
}

// createPhysicalFile å‰µå»ºå¯¦é«”æª”æ¡ˆ
func (tds *TestDeduplicationService) createPhysicalFile(filename, content string) (string, error) {
	filePath := filepath.Join(tds.tempDir, filename)
	return filePath, os.WriteFile(filePath, []byte(content), 0644)
}

// TestBasicDeduplication æ¸¬è©¦åŸºæœ¬å»é‡åŠŸèƒ½
func TestBasicDeduplication(t *testing.T) {
	tds := setupTestEnvironment(t)
	defer tds.cleanup()

	// å‰µå»ºç¬¬ä¸€å€‹æª”æ¡ˆ
	file1Path, err := tds.createPhysicalFile("file1.txt", tds.testFiles["file1.txt"])
	if err != nil {
		t.Fatalf("Failed to create file1: %v", err)
	}

	file1 := models.File{
		Name:         "file1.txt",
		OriginalName: "file1.txt",
		FilePath:     file1Path,
		VirtualPath:  "/file1.txt",
		SHA256Hash:   tds.testHashes["file1.txt"],
		FileSize:     int64(len(tds.testFiles["file1.txt"])),
		MimeType:     "text/plain",
		UploadedBy:   1,
		IsDirectory:  false,
		IsDeleted:    false,
	}

	if err := tds.db.Create(&file1).Error; err != nil {
		t.Fatalf("Failed to create file1 record: %v", err)
	}

	// ä¸Šå‚³ç›¸åŒå…§å®¹çš„æª”æ¡ˆï¼ˆæ‡‰è©²è¢«å»é‡ï¼‰
	var existingFile models.File
	result := tds.db.Where("sha256_hash = ? AND is_deleted = ?", 
		tds.testHashes["file1_dup.txt"], false).First(&existingFile)

	if result.Error != nil {
		t.Fatalf("Expected to find existing file with same hash: %v", result.Error)
	}

	// é©—è­‰æ‰¾åˆ°çš„æª”æ¡ˆç¢ºå¯¦æ˜¯åŸå§‹æª”æ¡ˆ
	if existingFile.ID != file1.ID {
		t.Errorf("Expected to find file1, got file ID %d", existingFile.ID)
	}

	// å‰µå»ºå»é‡æª”æ¡ˆè¨˜éŒ„ï¼ˆä¸åŒè™›æ“¬è·¯å¾‘ä½†æŒ‡å‘ç›¸åŒå¯¦é«”æª”æ¡ˆï¼‰
	file1Dup := models.File{
		Name:         "file1_dup.txt",
		OriginalName: "file1_dup.txt",
		FilePath:     existingFile.FilePath, // ä½¿ç”¨ç›¸åŒçš„å¯¦é«”è·¯å¾‘
		VirtualPath:  "/file1_dup.txt",
		SHA256Hash:   tds.testHashes["file1_dup.txt"],
		FileSize:     int64(len(tds.testFiles["file1_dup.txt"])),
		MimeType:     "text/plain",
		UploadedBy:   1,
		IsDirectory:  false,
		IsDeleted:    false,
	}

	if err := tds.db.Create(&file1Dup).Error; err != nil {
		t.Fatalf("Failed to create duplicate file record: %v", err)
	}

	// é©—è­‰å…©å€‹æª”æ¡ˆè¨˜éŒ„æŒ‡å‘ç›¸åŒçš„å¯¦é«”æª”æ¡ˆ
	if file1.FilePath != file1Dup.FilePath {
		t.Errorf("Duplicate files should share same physical path: %s vs %s", 
			file1.FilePath, file1Dup.FilePath)
	}

	// é©—è­‰åªæœ‰ä¸€å€‹å¯¦é«”æª”æ¡ˆå­˜åœ¨
	if _, err := os.Stat(file1.FilePath); os.IsNotExist(err) {
		t.Errorf("Physical file should exist: %s", file1.FilePath)
	}

	t.Logf("âœ… Basic deduplication test passed")
}

// TestMultipleFileDeduplication æ¸¬è©¦å¤šæª”æ¡ˆå»é‡
func TestMultipleFileDeduplication(t *testing.T) {
	tds := setupTestEnvironment(t)
	defer tds.cleanup()

	// å‰µå»ºå¤šå€‹æª”æ¡ˆï¼ŒåŒ…æ‹¬é‡è¤‡å…§å®¹
	testCases := []struct {
		filename    string
		virtualPath string
	}{
		{"file1.txt", "/folder1/file1.txt"},
		{"file1_dup.txt", "/folder2/file1.txt"},
		{"file2.txt", "/file2.txt"},
		{"file3.bin", "/binary/file3.bin"},
		{"file3_dup.bin", "/backup/file3.bin"},
		{"empty.txt", "/empty1.txt"},
		{"empty_dup.txt", "/empty2.txt"},
	}

	physicalPaths := make(map[string]string) // hash -> physical path

	for _, tc := range testCases {
		content := tds.testFiles[tc.filename]
		hash := tds.testHashes[tc.filename]

		var filePath string
		if existingPath, exists := physicalPaths[hash]; exists {
			// ä½¿ç”¨ç¾æœ‰çš„å¯¦é«”æª”æ¡ˆ
			filePath = existingPath
		} else {
			// å‰µå»ºæ–°çš„å¯¦é«”æª”æ¡ˆ
			var err error
			filePath, err = tds.createPhysicalFile(tc.filename, content)
			if err != nil {
				t.Fatalf("Failed to create file %s: %v", tc.filename, err)
			}
			physicalPaths[hash] = filePath
		}

		file := models.File{
			Name:         tc.filename,
			OriginalName: tc.filename,
			FilePath:     filePath,
			VirtualPath:  tc.virtualPath,
			SHA256Hash:   hash,
			FileSize:     int64(len(content)),
			MimeType:     "application/octet-stream",
			UploadedBy:   1,
			IsDirectory:  false,
			IsDeleted:    false,
		}

		if err := tds.db.Create(&file).Error; err != nil {
			t.Fatalf("Failed to create file record %s: %v", tc.filename, err)
		}
	}

	// çµ±è¨ˆå»é‡æ•ˆæœ
	var totalFiles int64
	tds.db.Model(&models.File{}).Where("is_deleted = ?", false).Count(&totalFiles)

	uniqueHashes := make(map[string]bool)
	var files []models.File
	tds.db.Where("is_deleted = ?", false).Find(&files)

	for _, file := range files {
		uniqueHashes[file.SHA256Hash] = true
	}

	expectedUniqueFiles := 4 // file1, file2, file3, empty
	actualUniqueFiles := len(uniqueHashes)

	if actualUniqueFiles != expectedUniqueFiles {
		t.Errorf("Expected %d unique files, got %d", expectedUniqueFiles, actualUniqueFiles)
	}

	// é©—è­‰å„²å­˜ç©ºé–“ç¯€çœ
	var totalLogicalSize int64
	var totalPhysicalFiles int
	physicalFilesSeen := make(map[string]bool)

	for _, file := range files {
		totalLogicalSize += file.FileSize
		if !physicalFilesSeen[file.FilePath] {
			physicalFilesSeen[file.FilePath] = true
			totalPhysicalFiles++
		}
	}

	if totalPhysicalFiles != expectedUniqueFiles {
		t.Errorf("Expected %d physical files, got %d", expectedUniqueFiles, totalPhysicalFiles)
	}

	spaceSavingPercentage := float64(len(testCases)-totalPhysicalFiles) / float64(len(testCases)) * 100

	t.Logf("âœ… Multiple file deduplication test passed")
	t.Logf("ğŸ“Š Files created: %d, Physical files: %d, Space saved: %.1f%%", 
		len(testCases), totalPhysicalFiles, spaceSavingPercentage)
}

// TestDeduplicationWithDeletion æ¸¬è©¦åˆªé™¤æª”æ¡ˆæ™‚çš„å»é‡è™•ç†
func TestDeduplicationWithDeletion(t *testing.T) {
	tds := setupTestEnvironment(t)
	defer tds.cleanup()

	content := tds.testFiles["file1.txt"]
	hash := tds.testHashes["file1.txt"]

	// å‰µå»ºå¯¦é«”æª”æ¡ˆ
	physicalPath, err := tds.createPhysicalFile("shared.txt", content)
	if err != nil {
		t.Fatalf("Failed to create physical file: %v", err)
	}

	// å‰µå»ºä¸‰å€‹æª”æ¡ˆè¨˜éŒ„ï¼Œå…±äº«åŒä¸€å€‹å¯¦é«”æª”æ¡ˆ
	files := []models.File{
		{
			Name:         "file1.txt",
			OriginalName: "file1.txt",
			FilePath:     physicalPath,
			VirtualPath:  "/file1.txt",
			SHA256Hash:   hash,
			FileSize:     int64(len(content)),
			UploadedBy:   1,
		},
		{
			Name:         "file1_copy.txt",
			OriginalName: "file1_copy.txt", 
			FilePath:     physicalPath,
			VirtualPath:  "/backup/file1_copy.txt",
			SHA256Hash:   hash,
			FileSize:     int64(len(content)),
			UploadedBy:   1,
		},
		{
			Name:         "file1_backup.txt",
			OriginalName: "file1_backup.txt",
			FilePath:     physicalPath,
			VirtualPath:  "/archive/file1_backup.txt",
			SHA256Hash:   hash,
			FileSize:     int64(len(content)),
			UploadedBy:   1,
		},
	}

	for i := range files {
		if err := tds.db.Create(&files[i]).Error; err != nil {
			t.Fatalf("Failed to create file record %d: %v", i, err)
		}
	}

	// é©—è­‰å¯¦é«”æª”æ¡ˆå­˜åœ¨
	if _, err := os.Stat(physicalPath); os.IsNotExist(err) {
		t.Fatalf("Physical file should exist: %s", physicalPath)
	}

	// è»Ÿåˆªé™¤ç¬¬ä¸€å€‹æª”æ¡ˆ
	now := time.Now()
	files[0].IsDeleted = true
	files[0].DeletedAt = &now
	if err := tds.db.Save(&files[0]).Error; err != nil {
		t.Fatalf("Failed to soft delete file: %v", err)
	}

	// é©—è­‰å¯¦é«”æª”æ¡ˆä»ç„¶å­˜åœ¨ï¼ˆå› ç‚ºé‚„æœ‰å…¶ä»–æª”æ¡ˆä½¿ç”¨ï¼‰
	if _, err := os.Stat(physicalPath); os.IsNotExist(err) {
		t.Errorf("Physical file should still exist after soft delete: %s", physicalPath)
	}

	// è»Ÿåˆªé™¤ç¬¬äºŒå€‹æª”æ¡ˆ
	files[1].IsDeleted = true
	files[1].DeletedAt = &now
	if err := tds.db.Save(&files[1]).Error; err != nil {
		t.Fatalf("Failed to soft delete second file: %v", err)
	}

	// å¯¦é«”æª”æ¡ˆä»æ‡‰å­˜åœ¨
	if _, err := os.Stat(physicalPath); os.IsNotExist(err) {
		t.Errorf("Physical file should still exist after second soft delete: %s", physicalPath)
	}

	// æª¢æŸ¥é‚„æœ‰å¤šå°‘å€‹æ´»èºçš„æª”æ¡ˆä½¿ç”¨é€™å€‹å¯¦é«”æª”æ¡ˆ
	var activeFileCount int64
	tds.db.Model(&models.File{}).Where("file_path = ? AND is_deleted = ?", 
		physicalPath, false).Count(&activeFileCount)

	if activeFileCount != 1 {
		t.Errorf("Expected 1 active file using physical path, got %d", activeFileCount)
	}

	// è»Ÿåˆªé™¤æœ€å¾Œä¸€å€‹æª”æ¡ˆ
	files[2].IsDeleted = true
	files[2].DeletedAt = &now
	if err := tds.db.Save(&files[2]).Error; err != nil {
		t.Fatalf("Failed to soft delete last file: %v", err)
	}

	// ç¾åœ¨æ‡‰è©²æ²’æœ‰æ´»èºæª”æ¡ˆä½¿ç”¨é€™å€‹å¯¦é«”æª”æ¡ˆ
	tds.db.Model(&models.File{}).Where("file_path = ? AND is_deleted = ?", 
		physicalPath, false).Count(&activeFileCount)

	if activeFileCount != 0 {
		t.Errorf("Expected 0 active files using physical path, got %d", activeFileCount)
	}

	// å¯¦é«”æª”æ¡ˆæ‡‰è©²å¯ä»¥è¢«æ¸…ç†ï¼ˆé€™è£¡æˆ‘å€‘æ¨¡æ“¬æ¸…ç†éç¨‹ï¼‰
	// åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™å¯èƒ½ç”±å¾Œå°ä»»å‹™è™•ç†
	if activeFileCount == 0 {
		if err := os.Remove(physicalPath); err != nil {
			t.Errorf("Failed to clean up orphaned physical file: %v", err)
		}
	}

	t.Logf("âœ… Deduplication with deletion test passed")
}

// TestLargeFileDeduplication æ¸¬è©¦å¤§æª”æ¡ˆå»é‡
func TestLargeFileDeduplication(t *testing.T) {
	tds := setupTestEnvironment(t)
	defer tds.cleanup()

	// å‰µå»ºå¤§æª”æ¡ˆå…§å®¹ï¼ˆ1MBï¼‰
	largeContent := strings.Repeat("This is a large file content block. ", 28571) // ç´„ 1MB
	hash := sha256.Sum256([]byte(largeContent))
	hashString := fmt.Sprintf("%x", hash)

	// å‰µå»ºç¬¬ä¸€å€‹å¤§æª”æ¡ˆ
	largePath1, err := tds.createPhysicalFile("large1.dat", largeContent)
	if err != nil {
		t.Fatalf("Failed to create large file 1: %v", err)
	}

	file1 := models.File{
		Name:         "large1.dat",
		OriginalName: "large1.dat",
		FilePath:     largePath1,
		VirtualPath:  "/large1.dat",
		SHA256Hash:   hashString,
		FileSize:     int64(len(largeContent)),
		MimeType:     "application/octet-stream",
		UploadedBy:   1,
	}

	if err := tds.db.Create(&file1).Error; err != nil {
		t.Fatalf("Failed to create large file 1 record: %v", err)
	}

	// æ¨¡æ“¬ä¸Šå‚³ç›¸åŒçš„å¤§æª”æ¡ˆï¼ˆå»é‡ï¼‰
	file2 := models.File{
		Name:         "large2.dat",
		OriginalName: "large2.dat", 
		FilePath:     largePath1, // æŒ‡å‘ç›¸åŒå¯¦é«”æª”æ¡ˆ
		VirtualPath:  "/backup/large2.dat",
		SHA256Hash:   hashString,
		FileSize:     int64(len(largeContent)),
		MimeType:     "application/octet-stream",
		UploadedBy:   1,
	}

	if err := tds.db.Create(&file2).Error; err != nil {
		t.Fatalf("Failed to create large file 2 record: %v", err)
	}

	// é©—è­‰å„²å­˜ç©ºé–“ç¯€çœ
	var totalLogicalSize int64
	var files []models.File
	tds.db.Where("is_deleted = ?", false).Find(&files)

	for _, file := range files {
		totalLogicalSize += file.FileSize
	}

	// æª¢æŸ¥å¯¦é«”æª”æ¡ˆå¤§å°
	fileInfo, err := os.Stat(largePath1)
	if err != nil {
		t.Fatalf("Failed to stat physical file: %v", err)
	}

	physicalSize := fileInfo.Size()
	logicalSize := totalLogicalSize

	spaceSaved := logicalSize - physicalSize
	spaceSavingPercentage := float64(spaceSaved) / float64(logicalSize) * 100

	if spaceSavingPercentage < 45 { // æ‡‰è©²ç¯€çœç´„ 50%
		t.Errorf("Expected significant space savings for large file deduplication, got %.1f%%", 
			spaceSavingPercentage)
	}

	t.Logf("âœ… Large file deduplication test passed")
	t.Logf("ğŸ“Š Logical size: %d bytes, Physical size: %d bytes, Space saved: %.1f%%", 
		logicalSize, physicalSize, spaceSavingPercentage)
}

// TestHashCollisionHandling æ¸¬è©¦é›œæ¹Šç¢°æ’è™•ç†ï¼ˆç†è«–æ¸¬è©¦ï¼‰
func TestHashCollisionHandling(t *testing.T) {
	tds := setupTestEnvironment(t)
	defer tds.cleanup()

	// æ³¨æ„ï¼šé€™æ˜¯ç†è«–æ¸¬è©¦ï¼Œå¯¦éš› SHA256 ç¢°æ’æ¥µå…¶ç½•è¦‹
	// æ­¤æ¸¬è©¦ä¸»è¦é©—è­‰ç³»çµ±å¦‚ä½•è™•ç†ç›¸åŒé›œæ¹Šå€¼ä½†ä¸åŒå…§å®¹çš„æƒ…æ³

	// å‰µå»ºå…©å€‹æª”æ¡ˆï¼Œäººç‚ºè¨­ç½®ç›¸åŒçš„é›œæ¹Šå€¼ï¼ˆæ¨¡æ“¬ç¢°æ’ï¼‰
	content1 := "Content of file 1"
	content2 := "Content of file 2 (different)"
	fakeHash := "1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef"

	path1, err := tds.createPhysicalFile("file1.txt", content1)
	if err != nil {
		t.Fatalf("Failed to create file 1: %v", err)
	}

	path2, err := tds.createPhysicalFile("file2.txt", content2)
	if err != nil {
		t.Fatalf("Failed to create file 2: %v", err)
	}

	file1 := models.File{
		Name:         "file1.txt",
		OriginalName: "file1.txt",
		FilePath:     path1,
		VirtualPath:  "/file1.txt", 
		SHA256Hash:   fakeHash,
		FileSize:     int64(len(content1)),
		UploadedBy:   1,
	}

	if err := tds.db.Create(&file1).Error; err != nil {
		t.Fatalf("Failed to create file 1 record: %v", err)
	}

	// å˜—è©¦å‰µå»ºç¬¬äºŒå€‹æª”æ¡ˆï¼ˆç›¸åŒé›œæ¹Šå€¼ï¼‰
	// åœ¨çœŸå¯¦ç³»çµ±ä¸­ï¼Œæ‡‰è©²æœ‰é¡å¤–é©—è­‰ä¾†æª¢æ¸¬é€™ç¨®æƒ…æ³
	file2 := models.File{
		Name:         "file2.txt",
		OriginalName: "file2.txt",
		FilePath:     path2, // ä¸åŒçš„å¯¦é«”è·¯å¾‘
		VirtualPath:  "/file2.txt",
		SHA256Hash:   fakeHash, // ç›¸åŒçš„é›œæ¹Šå€¼
		FileSize:     int64(len(content2)),
		UploadedBy:   1,
	}

	if err := tds.db.Create(&file2).Error; err != nil {
		t.Fatalf("Failed to create file 2 record: %v", err)
	}

	// é©—è­‰å…©å€‹æª”æ¡ˆéƒ½å­˜åœ¨ä¸”æœ‰ä¸åŒçš„å¯¦é«”è·¯å¾‘
	var filesWithSameHash []models.File
	tds.db.Where("sha256_hash = ?", fakeHash).Find(&filesWithSameHash)

	if len(filesWithSameHash) != 2 {
		t.Errorf("Expected 2 files with same hash, got %d", len(filesWithSameHash))
	}

	// åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œç³»çµ±æ‡‰è©²æª¢æ¸¬åˆ°é€™ç¨®ç•°å¸¸æƒ…æ³ä¸¦è¨˜éŒ„è­¦å‘Š
	t.Logf("âš ï¸  Hash collision handling test completed (theoretical scenario)")
	t.Logf("ğŸ’¡ In production, additional content verification should be implemented")
}

// BenchmarkDeduplicationPerformance æ•ˆèƒ½åŸºæº–æ¸¬è©¦
func BenchmarkDeduplicationPerformance(b *testing.B) {
	tds := setupTestEnvironment(&testing.T{})
	defer tds.cleanup()

	testContent := "This is test content for performance benchmarking"
	hash := fmt.Sprintf("%x", sha256.Sum256([]byte(testContent)))

	b.ResetTimer()

	for i := 0; i < b.N; i++ {
		// æ¨¡æ“¬å»é‡æŸ¥è©¢
		var existingFile models.File
		tds.db.Where("sha256_hash = ? AND is_deleted = ?", hash, false).First(&existingFile)
	}
}