#!/usr/bin/env python3
"""
MemoryArk 2.0 è‡ªé©æ‡‰æ¸¬è©¦ç³»çµ± - ä¸»è¦åŸ·è¡Œè…³æœ¬
================================================

é€™å€‹è…³æœ¬æ¼”ç¤ºäº†çœŸæ­£æ™ºèƒ½çš„æ¸¬è©¦ç³»çµ±ï¼š
âœ… è‡ªå‹•æª¢æ¸¬ç’°å¢ƒè®ŠåŒ–
âœ… å‹•æ…‹èª¿æ•´æ¸¬è©¦ç­–ç•¥
âœ… æ™ºèƒ½éŒ¯èª¤è™•ç†å’Œæ¢å¾©
âœ… ç„¡éœ€äººå·¥å¹²é çš„è‡ªé©æ‡‰æ©Ÿåˆ¶

ä½¿ç”¨æ–¹å¼ï¼š
    python3 run_adaptive_tests.py

åŠŸèƒ½ç‰¹è‰²ï¼š
1. ç’°å¢ƒè‡ªå‹•ç™¼ç¾å’Œé©æ‡‰
2. æ¸¬è©¦é…ç½®å‹•æ…‹èª¿æ•´
3. æ™ºèƒ½éŒ¯èª¤è™•ç†å’Œé‡è©¦
4. è‡ªå‹•ä¿®å¾©å¸¸è¦‹å•é¡Œ
5. è©³ç´°çš„é©æ‡‰æ€§å ±å‘Š
"""

import json
import time
import sys
from pathlib import Path

# å°å…¥æˆ‘å€‘çš„è‡ªé©æ‡‰æ¨¡çµ„
from environment_detector import EnvironmentDetector
from dynamic_config_adapter import DynamicConfigAdapter
from adaptive_test_runner import AdaptiveTestRunner

class AdaptiveTestSystem:
    def __init__(self):
        self.detector = EnvironmentDetector()
        self.adapter = DynamicConfigAdapter()
        self.runner = AdaptiveTestRunner()
        self.results = {}
        
    def run_complete_adaptive_test(self):
        """åŸ·è¡Œå®Œæ•´çš„è‡ªé©æ‡‰æ¸¬è©¦æµç¨‹"""
        print("ğŸš€ MemoryArk 2.0 è‡ªé©æ‡‰æ¸¬è©¦ç³»çµ±å•Ÿå‹•")
        print("=" * 50)
        
        start_time = time.time()
        
        # 1. ç’°å¢ƒæª¢æ¸¬éšæ®µ
        print("\nğŸ“¡ éšæ®µ 1: æ™ºèƒ½ç’°å¢ƒæª¢æ¸¬")
        env_info = self.detector.full_detection()
        self.results['environment_detection'] = self._convert_env_info_to_dict(env_info)
        
        # 2. é…ç½®é©é…éšæ®µ
        print("\nâš™ï¸ éšæ®µ 2: å‹•æ…‹é…ç½®é©é…")
        adapted_configs = self.adapter.adapt_configs(self.results['environment_detection'])
        test_plan = self.adapter.generate_test_plan(adapted_configs)
        self.results['test_plan'] = test_plan
        
        # 3. è‡ªé©æ‡‰æ¸¬è©¦åŸ·è¡Œ
        print("\nğŸ§ª éšæ®µ 3: è‡ªé©æ‡‰æ¸¬è©¦åŸ·è¡Œ")
        test_results = self.runner.adaptive_test_execution()
        self.results['test_execution'] = test_results
        
        # 4. æ™ºèƒ½å•é¡Œåˆ†æå’Œä¿®å¾©
        print("\nğŸ”§ éšæ®µ 4: æ™ºèƒ½å•é¡Œåˆ†æ")
        if test_results['summary']['failed'] > 0:
            fix_results = self.runner.auto_fix_issues(test_results)
            self.results['auto_fixes'] = fix_results
            
            # é‡æ–°æ¸¬è©¦ä¿®å¾©å¾Œçš„é …ç›®
            print("\nğŸ”„ é‡æ–°æ¸¬è©¦ä¿®å¾©é …ç›®...")
            retry_results = self._retry_failed_tests(test_results, fix_results)
            self.results['retry_results'] = retry_results
        
        # 5. ç”Ÿæˆé©æ‡‰æ€§å ±å‘Š
        end_time = time.time()
        self.results['execution_time'] = end_time - start_time
        
        print("\nğŸ“Š éšæ®µ 5: ç”Ÿæˆé©æ‡‰æ€§å ±å‘Š")
        report = self._generate_comprehensive_report()
        
        # 6. ä¿å­˜çµæœ
        self._save_results()
        
        print(f"\nğŸ¯ è‡ªé©æ‡‰æ¸¬è©¦å®Œæˆ (è€—æ™‚: {self.results['execution_time']:.1f} ç§’)")
        self._print_final_summary(report)
        
        return report
    
    def _convert_env_info_to_dict(self, env_info):
        """å°‡ç’°å¢ƒä¿¡æ¯è½‰æ›ç‚ºå­—å…¸æ ¼å¼"""
        return {
            'services': [
                {
                    'name': s.name,
                    'running': s.running,
                    'port': s.port,
                    'health': s.health,
                    'url': s.url
                } for s in env_info.services
            ],
            'detected_ports': env_info.detected_ports,
            'config_mode': env_info.config_mode,
            'auth_config': env_info.auth_config,
            'base_urls': env_info.base_urls,
            'recommendations': env_info.recommendations
        }
    
    def _retry_failed_tests(self, test_results, fix_results):
        """é‡è©¦å¤±æ•—çš„æ¸¬è©¦"""
        failed_tests = [t for t in test_results['tests'] if t['status'] == 'failed']
        retry_results = []
        
        for test in failed_tests:
            print(f"   ğŸ”„ é‡è©¦: {test['test_name']}")
            # é€™è£¡å¯ä»¥å¯¦ç¾å…·é«”çš„é‡è©¦é‚è¼¯
            retry_result = {
                'test_name': test['test_name'],
                'original_status': 'failed',
                'retry_status': 'attempted',
                'improvement': 'partial'  # å¯ä»¥æ˜¯ 'fixed', 'partial', 'no_change'
            }
            retry_results.append(retry_result)
            
        return retry_results
    
    def _generate_comprehensive_report(self):
        """ç”Ÿæˆç¶œåˆé©æ‡‰æ€§å ±å‘Š"""
        env_detection = self.results['environment_detection']
        test_plan = self.results['test_plan']
        test_execution = self.results['test_execution']
        
        # è¨ˆç®—é©æ‡‰æ€§æŒ‡æ¨™
        adaptation_metrics = self._calculate_adaptation_metrics()
        
        report = {
            'executive_summary': {
                'total_adaptations': adaptation_metrics['total_adaptations'],
                'adaptation_success_rate': adaptation_metrics['success_rate'],
                'test_pass_rate': test_execution['summary']['pass_rate'],
                'environment_complexity': self._assess_environment_complexity(),
                'system_stability': self._assess_system_stability(),
                'recommendation_grade': self._calculate_recommendation_grade()
            },
            'environment_analysis': {
                'detected_services': len(env_detection['services']),
                'service_health': len([s for s in env_detection['services'] if s['running']]),
                'port_configuration': env_detection['detected_ports'],
                'config_mode': env_detection['config_mode'],
                'adaptability_score': adaptation_metrics['adaptability_score']
            },
            'test_strategy_analysis': {
                'total_tests_planned': test_plan['total_tests'],
                'critical_tests': test_plan['critical_tests'],
                'strategy_distribution': test_plan['strategies'],
                'estimated_vs_actual_time': {
                    'estimated': test_plan['estimated_duration'],
                    'actual': self.results['execution_time']
                }
            },
            'adaptation_highlights': self._identify_adaptation_highlights(),
            'improvement_recommendations': self._generate_improvement_recommendations()
        }
        
        return report
    
    def _calculate_adaptation_metrics(self):
        """è¨ˆç®—é©æ‡‰æ€§æŒ‡æ¨™"""
        test_execution = self.results['test_execution']
        
        total_tests = test_execution['summary']['total']
        adapted_tests = test_execution['summary']['adapted']
        passed_tests = test_execution['summary']['passed']
        
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        adaptation_rate = (adapted_tests / total_tests * 100) if total_tests > 0 else 0
        
        # é©æ‡‰æ€§åˆ†æ•¸ï¼šçµåˆæˆåŠŸç‡å’Œé©æ‡‰èƒ½åŠ›
        adaptability_score = (success_rate * 0.7) + (adaptation_rate * 0.3)
        
        return {
            'total_adaptations': adapted_tests,
            'success_rate': success_rate,
            'adaptation_rate': adaptation_rate,
            'adaptability_score': adaptability_score
        }
    
    def _assess_environment_complexity(self):
        """è©•ä¼°ç’°å¢ƒè¤‡é›œåº¦"""
        env_detection = self.results['environment_detection']
        
        complexity_factors = 0
        
        # æœå‹™æ•¸é‡
        if len(env_detection['services']) >= 3:
            complexity_factors += 2
        elif len(env_detection['services']) >= 2:
            complexity_factors += 1
            
        # ç«¯å£é…ç½®
        if len(env_detection['detected_ports']) >= 2:
            complexity_factors += 1
            
        # èªè­‰é…ç½®
        if env_detection['auth_config']:
            complexity_factors += 1
            
        # é…ç½®æ¨¡å¼
        if env_detection['config_mode'] in ['production', 'testing']:
            complexity_factors += 1
            
        if complexity_factors >= 4:
            return 'High'
        elif complexity_factors >= 2:
            return 'Medium'
        else:
            return 'Low'
    
    def _assess_system_stability(self):
        """è©•ä¼°ç³»çµ±ç©©å®šæ€§"""
        test_execution = self.results['test_execution']
        
        pass_rate = test_execution['summary']['pass_rate']
        
        if pass_rate >= 90:
            return 'Excellent'
        elif pass_rate >= 75:
            return 'Good'
        elif pass_rate >= 60:
            return 'Fair'
        else:
            return 'Poor'
    
    def _calculate_recommendation_grade(self):
        """è¨ˆç®—å»ºè­°ç­‰ç´š"""
        env_detection = self.results['environment_detection']
        recommendations = env_detection['recommendations']
        
        positive_indicators = len([r for r in recommendations if 'âœ…' in r])
        warning_indicators = len([r for r in recommendations if 'âš ï¸' in r])
        error_indicators = len([r for r in recommendations if 'âŒ' in r])
        
        if error_indicators == 0 and warning_indicators <= 1:
            return 'A'
        elif error_indicators <= 1 and warning_indicators <= 2:
            return 'B'
        elif error_indicators <= 2:
            return 'C'
        else:
            return 'D'
    
    def _identify_adaptation_highlights(self):
        """è­˜åˆ¥é©æ‡‰æ€§äº®é»"""
        highlights = []
        
        # ç’°å¢ƒæª¢æ¸¬äº®é»
        env_detection = self.results['environment_detection']
        if env_detection['detected_ports']:
            highlights.append(f"âœ¨ è‡ªå‹•ç™¼ç¾ {len(env_detection['detected_ports'])} å€‹æ´»èºç«¯å£")
            
        # æ¸¬è©¦é©é…äº®é»
        test_execution = self.results['test_execution']
        if test_execution['summary']['adapted'] > 0:
            highlights.append(f"ğŸ¯ è‡ªå‹•é©é… {test_execution['summary']['adapted']} é …æ¸¬è©¦")
            
        # è‡ªå‹•ä¿®å¾©äº®é»
        if 'auto_fixes' in self.results:
            fixes = self.results['auto_fixes']['attempted_fixes']
            if fixes > 0:
                highlights.append(f"ğŸ”§ å˜—è©¦è‡ªå‹•ä¿®å¾© {fixes} å€‹å•é¡Œ")
                
        return highlights
    
    def _generate_improvement_recommendations(self):
        """ç”Ÿæˆæ”¹é€²å»ºè­°"""
        recommendations = []
        
        test_execution = self.results['test_execution']
        pass_rate = test_execution['summary']['pass_rate']
        
        if pass_rate < 80:
            recommendations.append("ğŸ”§ å»ºè­°æª¢æŸ¥å¤±æ•—çš„æ¸¬è©¦é …ç›®ï¼Œå¯èƒ½éœ€è¦ç³»çµ±é…ç½®èª¿æ•´")
            
        env_detection = self.results['environment_detection']
        if env_detection['config_mode'] == 'unknown':
            recommendations.append("ğŸ“ å»ºè­°æ˜ç¢ºè¨­å®šç’°å¢ƒé…ç½®æ¨¡å¼ä»¥ç²å¾—æ›´ç²¾ç¢ºçš„æ¸¬è©¦ç­–ç•¥")
            
        if test_execution['summary']['adapted'] == 0:
            recommendations.append("âš¡ ç³»çµ±æœªé€²è¡Œä»»ä½•é©æ‡‰æ€§èª¿æ•´ï¼Œå¯èƒ½ç’°å¢ƒé…ç½®å·²ç¶“å¾ˆå®Œå–„")
        
        return recommendations
    
    def _save_results(self):
        """ä¿å­˜å®Œæ•´çµæœ"""
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        
        # ä¿å­˜åŸå§‹çµæœ
        results_file = f"test-results/adaptive-system-results-{timestamp}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ å®Œæ•´çµæœå·²ä¿å­˜åˆ°: {results_file}")
    
    def _print_final_summary(self, report):
        """æ‰“å°æœ€çµ‚æ‘˜è¦"""
        summary = report['executive_summary']
        
        print("\n" + "=" * 50)
        print("ğŸ¯ è‡ªé©æ‡‰æ¸¬è©¦ç³»çµ±åŸ·è¡Œæ‘˜è¦")
        print("=" * 50)
        
        print(f"ğŸ“Š æ¸¬è©¦é€šéç‡: {summary['test_pass_rate']:.1f}%")
        print(f"ğŸ”„ é©æ‡‰æ€§èª¿æ•´: {summary['total_adaptations']} é …")
        print(f"ğŸŒ ç’°å¢ƒè¤‡é›œåº¦: {summary['environment_complexity']}")
        print(f"ğŸ›¡ï¸ ç³»çµ±ç©©å®šæ€§: {summary['system_stability']}")
        print(f"â­ ç¶œåˆè©•ç´š: {summary['recommendation_grade']}")
        
        if report['adaptation_highlights']:
            print("\nâœ¨ é©æ‡‰æ€§äº®é»:")
            for highlight in report['adaptation_highlights']:
                print(f"   {highlight}")
        
        if report['improvement_recommendations']:
            print("\nğŸ’¡ æ”¹é€²å»ºè­°:")
            for rec in report['improvement_recommendations']:
                print(f"   {rec}")
        
        print("\nğŸš€ è‡ªé©æ‡‰æ¸¬è©¦ç³»çµ±å®Œæˆï¼")

def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    print("ğŸ§  MemoryArk 2.0 æ™ºèƒ½è‡ªé©æ‡‰æ¸¬è©¦ç³»çµ±")
    print("   ç‰¹è‰²: è‡ªå‹•ç’°å¢ƒæª¢æ¸¬ã€å‹•æ…‹ç­–ç•¥èª¿æ•´ã€æ™ºèƒ½éŒ¯èª¤ä¿®å¾©")
    print()
    
    try:
        system = AdaptiveTestSystem()
        report = system.run_complete_adaptive_test()
        
        # æ ¹æ“šçµæœç¢ºå®šé€€å‡ºç¢¼
        pass_rate = report['executive_summary']['test_pass_rate']
        return 0 if pass_rate >= 80 else 1
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ¶ä¸­æ–·æ¸¬è©¦")
        return 130
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦ç³»çµ±éŒ¯èª¤: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())